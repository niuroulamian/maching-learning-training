{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次以英雄联盟对局胜负预测任务为基础，要求实现决策树算法相关细节，加深对算法的理解，并了解做机器学习任务的大致流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务介绍\n",
    "英雄联盟（League of Legends，LoL）是一个多人在线竞技游戏，由拳头游戏（Riot Games）公司出品。在游戏中，每位玩家控制一位有独特技能的英雄，红蓝两支队伍各有五位玩家进行对战，目标是摧毁对方的基地水晶。水晶有多座防御塔保护，通常需要先摧毁一些防御塔再摧毁水晶。玩家所控制的英雄起初非常弱，需要不断击杀小兵、野怪和对方英雄来获得金币、经验。经验可以提升英雄等级和技能等级，金币可以用来购买装备提升攻击、防御等属性。对战过程中一般没有己方单位在附近的地点是没有视野的，即无法看到对面单位，双方可以通过使用守卫来监视某个地点，洞察对面走向、制定战术。\n",
    "本数据集来自[Kaggle](https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min)，包含了9879场钻一到大师段位的单双排对局，对局双方几乎是同一水平。每条数据是前10分钟的对局情况，每支队伍有19个特征，红蓝双方共38个特征。这些特征包括英雄击杀、死亡，金钱、经验、等级情况等等。一局游戏一般会持续30至40分钟，但是实际前10分钟的局面很大程度上影响了之后胜负的走向。作为最成功的电子竞技游戏之一，对局数据、选手数据的量化与研究具有重要意义，可以启发游戏将来的发展和改进。\n",
    "\n",
    "本任务是希望同学们依据注释的要求，对代码中空缺部分进行填写，**完成决策树模型的详细实现**，根据已有的对局前10分钟特征信息，预测最后获胜方是蓝色方还是红色方，了解执行一个**机器学习任务的大致流程**，并**提交代码和实验报告**。第一次作业也是一个机器学习小实验的例子，之后的作业可能不再提供预处理等流程代码，由同学们自己设计实验完成代码编写。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入工具包\n",
    "pandas是数据分析和处理常用的工具包，非常适合处理行列表格数据。numpy是数学运算工具包，支持高效的矩阵、向量运算。sklearn是机器学习常用工具包，包括了一些已经实现好的简单模型和一些常用数据处理方法、评价指标等函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd # 数据处理\n",
    "import numpy as np # 数学运算\n",
    "from sklearn.model_selection import train_test_split, cross_validate # 划分数据集函数\n",
    "from sklearn.metrics import accuracy_score # 准确率函数\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "RANDOM_SEED = 2020 # 固定随机种子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入数据\n",
    "假设数据文件放在`./data/`目录下，标准的csv文件可以用pandas里的`read_csv()`函数直接读入。文件共有40列，38个特征（红蓝方各19），1个标签列（blueWins），和一个对局标号（gameId）。对局标号不是标签也不是特征，可以舍去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = './data/high_diamond_ranked_10min.csv' # 数据路径\n",
    "data_df = pd.read_csv(csv_data, sep=',') # 读入csv文件为pandas的DataFrame\n",
    "data_df = data_df.drop(columns='gameId') # 舍去对局标号列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  数据概览\n",
    "对于一个机器学习问题，在拿到任务和数据后，首先需要观察数据的情况，比如我们可以通过`.iloc[0]`取出数据的第一行并输出。不难看出每个特征都存成了float64浮点数，该对局蓝色方开局10分钟有小优势。同时也可以发现有些特征列是重复冗余的，比如blueGoldDiff表示蓝色队金币优势，redGoldDiff表示红色方金币优势，这两个特征是完全对称的互为相反数。blueCSPerMin是蓝色方每分钟击杀小兵数，它乘10就是10分钟所有小兵击杀数blueTotalMinionsKilled。在之后的特征处理过程中可以考虑去除这些冗余特征。\n",
    "另外，pandas有非常方便的`describe()`函数，可以直接通过DataFrame进行调用，可以展示每一列数据的一些统计信息，对数据分布情况有大致了解，比如blueKills蓝色方击杀英雄数在前十分钟的平均数是6.14、方差为2.93，中位数是6，百分之五十以上的对局中该特征在4-8之间，等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blueWins                            0.0\n",
      "blueWardsPlaced                    28.0\n",
      "blueWardsDestroyed                  2.0\n",
      "blueFirstBlood                      1.0\n",
      "blueKills                           9.0\n",
      "blueDeaths                          6.0\n",
      "blueAssists                        11.0\n",
      "blueEliteMonsters                   0.0\n",
      "blueDragons                         0.0\n",
      "blueHeralds                         0.0\n",
      "blueTowersDestroyed                 0.0\n",
      "blueTotalGold                   17210.0\n",
      "blueAvgLevel                        6.6\n",
      "blueTotalExperience             17039.0\n",
      "blueTotalMinionsKilled            195.0\n",
      "blueTotalJungleMinionsKilled       36.0\n",
      "blueGoldDiff                      643.0\n",
      "blueExperienceDiff                 -8.0\n",
      "blueCSPerMin                       19.5\n",
      "blueGoldPerMin                   1721.0\n",
      "redWardsPlaced                     15.0\n",
      "redWardsDestroyed                   6.0\n",
      "redFirstBlood                       0.0\n",
      "redKills                            6.0\n",
      "redDeaths                           9.0\n",
      "redAssists                          8.0\n",
      "redEliteMonsters                    0.0\n",
      "redDragons                          0.0\n",
      "redHeralds                          0.0\n",
      "redTowersDestroyed                  0.0\n",
      "redTotalGold                    16567.0\n",
      "redAvgLevel                         6.8\n",
      "redTotalExperience              17047.0\n",
      "redTotalMinionsKilled             197.0\n",
      "redTotalJungleMinionsKilled        55.0\n",
      "redGoldDiff                      -643.0\n",
      "redExperienceDiff                   8.0\n",
      "redCSPerMin                        19.7\n",
      "redGoldPerMin                    1656.7\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blueWins</th>\n",
       "      <th>blueWardsPlaced</th>\n",
       "      <th>blueWardsDestroyed</th>\n",
       "      <th>blueFirstBlood</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueAssists</th>\n",
       "      <th>blueEliteMonsters</th>\n",
       "      <th>blueDragons</th>\n",
       "      <th>blueHeralds</th>\n",
       "      <th>...</th>\n",
       "      <th>redTowersDestroyed</th>\n",
       "      <th>redTotalGold</th>\n",
       "      <th>redAvgLevel</th>\n",
       "      <th>redTotalExperience</th>\n",
       "      <th>redTotalMinionsKilled</th>\n",
       "      <th>redTotalJungleMinionsKilled</th>\n",
       "      <th>redGoldDiff</th>\n",
       "      <th>redExperienceDiff</th>\n",
       "      <th>redCSPerMin</th>\n",
       "      <th>redGoldPerMin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499038</td>\n",
       "      <td>22.288288</td>\n",
       "      <td>2.824881</td>\n",
       "      <td>0.504808</td>\n",
       "      <td>6.183925</td>\n",
       "      <td>6.137666</td>\n",
       "      <td>6.645106</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>0.361980</td>\n",
       "      <td>0.187974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>16489.041401</td>\n",
       "      <td>6.925316</td>\n",
       "      <td>17961.730438</td>\n",
       "      <td>217.349226</td>\n",
       "      <td>51.313088</td>\n",
       "      <td>-14.414111</td>\n",
       "      <td>33.620306</td>\n",
       "      <td>21.734923</td>\n",
       "      <td>1648.904140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500024</td>\n",
       "      <td>18.019177</td>\n",
       "      <td>2.174998</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>3.011028</td>\n",
       "      <td>2.933818</td>\n",
       "      <td>4.064520</td>\n",
       "      <td>0.625527</td>\n",
       "      <td>0.480597</td>\n",
       "      <td>0.390712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>1490.888406</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>1198.583912</td>\n",
       "      <td>21.911668</td>\n",
       "      <td>10.027885</td>\n",
       "      <td>2453.349179</td>\n",
       "      <td>1920.370438</td>\n",
       "      <td>2.191167</td>\n",
       "      <td>149.088841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11212.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>10465.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-11467.000000</td>\n",
       "      <td>-8348.000000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>1121.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15427.500000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>17209.500000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>-1596.000000</td>\n",
       "      <td>-1212.000000</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>1542.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16378.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17974.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>1637.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17418.500000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>18764.500000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1585.500000</td>\n",
       "      <td>1290.500000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>1741.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22732.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>22269.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10830.000000</td>\n",
       "      <td>9333.000000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>2273.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          blueWins  blueWardsPlaced  blueWardsDestroyed  blueFirstBlood  \\\n",
       "count  9879.000000      9879.000000         9879.000000     9879.000000   \n",
       "mean      0.499038        22.288288            2.824881        0.504808   \n",
       "std       0.500024        18.019177            2.174998        0.500002   \n",
       "min       0.000000         5.000000            0.000000        0.000000   \n",
       "25%       0.000000        14.000000            1.000000        0.000000   \n",
       "50%       0.000000        16.000000            3.000000        1.000000   \n",
       "75%       1.000000        20.000000            4.000000        1.000000   \n",
       "max       1.000000       250.000000           27.000000        1.000000   \n",
       "\n",
       "         blueKills   blueDeaths  blueAssists  blueEliteMonsters  blueDragons  \\\n",
       "count  9879.000000  9879.000000  9879.000000        9879.000000  9879.000000   \n",
       "mean      6.183925     6.137666     6.645106           0.549954     0.361980   \n",
       "std       3.011028     2.933818     4.064520           0.625527     0.480597   \n",
       "min       0.000000     0.000000     0.000000           0.000000     0.000000   \n",
       "25%       4.000000     4.000000     4.000000           0.000000     0.000000   \n",
       "50%       6.000000     6.000000     6.000000           0.000000     0.000000   \n",
       "75%       8.000000     8.000000     9.000000           1.000000     1.000000   \n",
       "max      22.000000    22.000000    29.000000           2.000000     1.000000   \n",
       "\n",
       "       blueHeralds  ...  redTowersDestroyed  redTotalGold  redAvgLevel  \\\n",
       "count  9879.000000  ...         9879.000000   9879.000000  9879.000000   \n",
       "mean      0.187974  ...            0.043021  16489.041401     6.925316   \n",
       "std       0.390712  ...            0.216900   1490.888406     0.305311   \n",
       "min       0.000000  ...            0.000000  11212.000000     4.800000   \n",
       "25%       0.000000  ...            0.000000  15427.500000     6.800000   \n",
       "50%       0.000000  ...            0.000000  16378.000000     7.000000   \n",
       "75%       0.000000  ...            0.000000  17418.500000     7.200000   \n",
       "max       1.000000  ...            2.000000  22732.000000     8.200000   \n",
       "\n",
       "       redTotalExperience  redTotalMinionsKilled  redTotalJungleMinionsKilled  \\\n",
       "count         9879.000000            9879.000000                  9879.000000   \n",
       "mean         17961.730438             217.349226                    51.313088   \n",
       "std           1198.583912              21.911668                    10.027885   \n",
       "min          10465.000000             107.000000                     4.000000   \n",
       "25%          17209.500000             203.000000                    44.000000   \n",
       "50%          17974.000000             218.000000                    51.000000   \n",
       "75%          18764.500000             233.000000                    57.000000   \n",
       "max          22269.000000             289.000000                    92.000000   \n",
       "\n",
       "        redGoldDiff  redExperienceDiff  redCSPerMin  redGoldPerMin  \n",
       "count   9879.000000        9879.000000  9879.000000    9879.000000  \n",
       "mean     -14.414111          33.620306    21.734923    1648.904140  \n",
       "std     2453.349179        1920.370438     2.191167     149.088841  \n",
       "min   -11467.000000       -8348.000000    10.700000    1121.200000  \n",
       "25%    -1596.000000       -1212.000000    20.300000    1542.750000  \n",
       "50%      -14.000000          28.000000    21.800000    1637.800000  \n",
       "75%     1585.500000        1290.500000    23.300000    1741.850000  \n",
       "max    10830.000000        9333.000000    28.900000    2273.200000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_df.iloc[0]) # 输出第一行数据\n",
    "data_df.describe() # 每列特征的简单统计信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增删特征\n",
    "传统的机器学习模型大部分都是基于特征的，因此特征工程是机器学习中非常重要的一步。有时构造一个好的特征比改进一个模型带来的提升更大。这里简单展示一些特征处理的例子。首先，上面提到，特征列中有些特征信息是完全冗余的，会给模型带来不必要的计算量，可以去除。其次，相比于红蓝双方击杀、助攻的绝对值，可能双方击杀英雄的差值更能体现出当前对战的局势。因此，我们可以构造红蓝双方对应特征的差值。数据文件中已有的差值是金币差GoldDiff和经验差ExperienceDiff，实际上每个对应特征都可以构造这样的差值特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 舍去不需要构造差值的特征列\n",
    "drop_features = ['blueGoldDiff', 'redGoldDiff',\n",
    "                 'blueExperienceDiff', 'redExperienceDiff',\n",
    "                 'blueCSPerMin', 'redCSPerMin',\n",
    "                 'blueGoldPerMin', 'redGoldPerMin']\n",
    "df = data_df.drop(columns=drop_features)\n",
    "\n",
    "# 构造红蓝双方对应特征的差值特征\n",
    "for c in df.columns:\n",
    "    if c.startswith('red'):\n",
    "        info = c[3:] # 取出特征名字部分\n",
    "        df['br' + info] = df['blue' + info] - df['red' + info]\n",
    "        df = df.drop(columns=['blue' + info, 'red' + info]) # 舍去原有特征列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征离散化\n",
    "决策树ID3算法一般是基于离散特征的，本例中存在很多连续的数值特征，例如队伍金币。直接应用该算法每个值当作一个该特征的一个取值可能造成严重的过拟合，因此需要对特征进行离散化，即将一定范围内的值映射成一个值，例如对用户年龄特征，将0-10映射到0，11-18映射到1，19-25映射到2，25-30映射到3，等等类似，然后在决策树构建时使用映射后的值计算信息增益。\n",
    "\n",
    "***本小节要求实现特征离散化，请补全相关代码***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "discrete_df = df.copy() # 先复制一份数据\n",
    "for c in df.columns[1:]: # 遍历每一列特征，跳过标签列(blueWins)\n",
    "    '''\n",
    "    请离散化每一列特征，即discrete_df[c] = ...\n",
    "    \n",
    "    提示：\n",
    "    对于有些特征本身取值就很少，可以跳过即 if ... : continue\n",
    "    对于其他特征，可以使用等区间离散化、等密度离散化或一些其他离散化方法\n",
    "    可参考使用pandas.cut或qcut\n",
    "    '''\n",
    "    discrete_df[c] = pd.qcut(df[c], q=4, labels=False, duplicates='drop')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集准备\n",
    "构建机器学习模型前要构建训练和测试的数据集。在本例中首先需要分开标签和特征，标签是不能作为模型的输入特征的，就好比作业和试卷答案不能在做题和考试前就告诉学生。测试一个模型在一个任务上的效果至少需要训练集和测试集，训练集用来训练模型的参数，好比学生做作业获得知识，测试集用来测试模型效果，好比期末考试考察学生学习情况。测试集的样本不应该出现在训练集中，否则会造成模型效果估计偏高，好比考试时出的题如果是作业题中出现过的，会造成考试分数不能准确衡量学生的学习情况，估计值偏高。划分训练集和测试集有多种方法，下面首先介绍的是随机取一部分如20%作测试集，剩下作训练集。sklearn提供了相关工具函数`train_test_split`。sklearn的输入输出一般为numpy的array矩阵，需要先将pandas的DataFrame取出为numpy的array矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9879, 15) (6323, 15) (1580, 15) (1976, 15) (9879,) (6323,) (1580,) (1976,)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# split_train_val: 划分训练集和验证集\n",
    "# -------------------------\n",
    "def split_train_val(x, y, val_ratio=0.2, shuffle=True, random_state=None):\n",
    "    \"\"\"\n",
    "    将数据划分为训练集和验证集。\n",
    "\n",
    "    x: numpy 2D array (n_samples, n_features)\n",
    "    y: numpy 1D array (n_samples,)\n",
    "    val_ratio: 验证集占比，例如 0.2 = 20%\n",
    "    shuffle: 是否打乱数据\n",
    "    random_state: 随机种子保证可复现\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    n_samples = x.shape[0]\n",
    "\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        idx = np.arange(n_samples)\n",
    "        rng.shuffle(idx)\n",
    "        x = x[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "    # 验证集数量\n",
    "    val_size = int(n_samples * val_ratio)\n",
    "\n",
    "    X_val = x[:val_size]\n",
    "    y_val = y[:val_size]\n",
    "    X_train = x[val_size:]\n",
    "    y_train = y[val_size:]\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "all_y = discrete_df['blueWins'].values # 所有标签数据\n",
    "feature_names = discrete_df.columns[1:] # 所有特征的名称\n",
    "all_x = discrete_df[feature_names].values # 所有原始特征值，pandas的DataFrame.values取出为numpy的array矩阵\n",
    "\n",
    "# 划分训练集，验证集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_x, all_y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "x_train, x_val, y_train, y_val = split_train_val(x_train, y_train, val_ratio=0.2, random_state=42)\n",
    "print(all_x.shape, x_train.shape, x_val.shape, x_test.shape, all_y.shape, y_train.shape, y_val.shape, y_test.shape) # 输出训练集数据维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  决策树模型的实现\n",
    "***本小节要求实现决策树模型，请补全算法代码***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 1 1]\n",
      "accuracy: 0.7146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定义决策树类\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, classes, features,\n",
    "                 max_depth=10, min_samples_split=10,\n",
    "                 impurity_t='entropy'):\n",
    "        '''\n",
    "        传入一些可能用到的模型参数，也可能不会用到\n",
    "        classes表示模型分类总共有几类\n",
    "        features是每个特征的名字，也方便查询总的共特征数\n",
    "        max_depth表示构建决策树时的最大深度\n",
    "        min_samples_split表示构建决策树分裂节点时，如果到达该节点的样本数小于该值则不再分裂\n",
    "        impurity_t表示计算混杂度（不纯度）的计算方式，例如entropy或gini\n",
    "        '''\n",
    "        self.classes = classes\n",
    "        self.features = features\n",
    "        self.x_val = None\n",
    "        self.y_val = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.impurity_t = impurity_t\n",
    "        self.root = None # 定义根节点，未训练时为空\n",
    "\n",
    "    '''\n",
    "    请实现决策树算法，使得fit函数和predict函数可以正常调用，跑通之后的测试代码，\n",
    "    要求之后测试代码输出的准确率大于0.6。\n",
    "    \n",
    "    提示：\n",
    "    可以定义额外一些函数，例如\n",
    "    impurity()用来计算混杂度\n",
    "    gain()调用impurity用来计算信息增益\n",
    "    expand_node()训练时递归函数分裂节点，考虑不同情况\n",
    "        1. 无需分裂 或 达到分裂阈值\n",
    "        2. 调用gain()找到最佳分裂特征，递归调用expand_node\n",
    "        3. 找不到有用的分裂特征\n",
    "        fit函数调用该函数返回根节点\n",
    "    traverse_node()预测时遍历节点，考虑不同情况\n",
    "        1. 已经到达叶节点，则返回分类结果\n",
    "        2. 该特征取值在训练集中未出现过\n",
    "        3. 依据特征取值进入相应子节点，递归调用traverse_node\n",
    "    当然也可以有其他实现方式。\n",
    "\n",
    "    '''\n",
    "    # -------------------------\n",
    "    # expand_node: 递归分裂节点\n",
    "    # -------------------------\n",
    "    def expand_node(self, x, y, depth):\n",
    "        # 1. 停止条件：纯节点\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return {\"leaf\": True, \"class\": y[0]}\n",
    "\n",
    "        # 深度限制 / 样本太少\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "                len(y) < self.min_samples_split:\n",
    "            vals, counts = np.unique(y, return_counts=True)\n",
    "            return {\"leaf\": True, \"class\": vals[np.argmax(counts)]}\n",
    "\n",
    "        # 2. 寻找最佳分裂特征\n",
    "        best_feature = None\n",
    "        best_gain = 0.0\n",
    "\n",
    "        for i in range(x.shape[1]):\n",
    "            g = self.gain(x[:, i], y)\n",
    "            if g > best_gain:\n",
    "                best_gain = g\n",
    "                best_feature = i\n",
    "\n",
    "        # 3. 前剪枝：无有效分裂（信息增益太小）\n",
    "        if best_feature is None or best_gain <= 1e-12:\n",
    "            vals, counts = np.unique(y, return_counts=True)\n",
    "            return {\"leaf\": True, \"class\": vals[np.argmax(counts)]}\n",
    "\n",
    "        # ------- 前剪枝：验证集剪枝 -------\n",
    "        if self.x_val is not None:\n",
    "            # 当前节点作为叶节点的分类（多数类）\n",
    "            vals, counts = np.unique(y, return_counts=True)\n",
    "            majority_class = vals[np.argmax(counts)]\n",
    "            # 当 best_gain 非常小，也可以不分裂\n",
    "            if best_gain < 1e-5:\n",
    "                return {\"leaf\": True, \"class\": majority_class}\n",
    "        # ------- 前剪枝结束 ------\n",
    "\n",
    "        # 4. 构建子节点并递归\n",
    "        node = {\n",
    "            \"leaf\": False,\n",
    "            \"feature\": best_feature,\n",
    "            \"children\": {}\n",
    "        }\n",
    "\n",
    "        values = np.unique(x[:, best_feature])\n",
    "        for v in values:\n",
    "            idx = x[:, best_feature] == v\n",
    "            child = self.expand_node(x[idx], y[idx], depth + 1)\n",
    "            node[\"children\"][v] = child\n",
    "\n",
    "        return node\n",
    "\n",
    "    # -------------------------\n",
    "    # gain: 计算特征 i 的信息增益\n",
    "    # -------------------------\n",
    "    def gain(self, feature_col, labels):\n",
    "        root_imp = self.impurity(labels)\n",
    "        values, idx = np.unique(feature_col, return_inverse=True)\n",
    "\n",
    "        split_impurity = 0.0\n",
    "        for v in range(len(values)):\n",
    "            subset = labels[idx == v]\n",
    "            split_impurity += (len(subset) / len(labels)) * self.impurity(subset)\n",
    "\n",
    "        return root_imp - split_impurity\n",
    "\n",
    "    # -------------------------\n",
    "    # impurity: 计算混杂度（entropy）\n",
    "    # -------------------------\n",
    "    def impurity(self, labels):\n",
    "        _, counts = np.unique(labels, return_counts=True)\n",
    "        probs = counts / len(labels)\n",
    "        return -np.sum(probs * np.log2(probs + 1e-9))   # 防止 log(0)\n",
    "\n",
    "    def fit(self, feature, label, val_feature=None, val_label=None):\n",
    "        assert len(self.features) == len(feature[0]) # 输入数据的特征数目应该和模型定义时的特征数目相同\n",
    "        '''\n",
    "        训练模型\n",
    "        feature为二维numpy（n*m）数组，每行表示一个样本，有m个特征\n",
    "        label为一维numpy（n）数组，表示每个样本的分类标签\n",
    "        \n",
    "        提示：一种可能的实现方式为\n",
    "        self.root = self.expand_node(feature, label, depth=1) # 从根节点开始分裂，模型记录根节点\n",
    "        '''\n",
    "        # -------------------------\n",
    "        # fit 函数：构造整棵树\n",
    "        # -------------------------\n",
    "        x = np.asarray(feature)\n",
    "        y = np.asarray(label)\n",
    "        self.x_val = val_feature\n",
    "        self.y_val = val_label\n",
    "        self.root = self.expand_node(x, y, depth=1)\n",
    "        return self\n",
    "\n",
    "    def traverse_node(self, node, x):\n",
    "        if node[\"leaf\"]:\n",
    "            return node[\"class\"]\n",
    "\n",
    "        feature = node[\"feature\"]\n",
    "        value = x[feature]\n",
    "\n",
    "        if value not in node[\"children\"]:\n",
    "            classes = []\n",
    "            for child in node[\"children\"].values():\n",
    "                if child[\"leaf\"]:\n",
    "                    classes.append(child[\"class\"])\n",
    "\n",
    "            if classes:\n",
    "                vals, counts = np.unique(classes, return_counts=True)\n",
    "                return vals[np.argmax(counts)]\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        return self.traverse_node(node[\"children\"][value], x)\n",
    "\n",
    "    def predict(self, feature):\n",
    "        assert len(feature.shape) == 1 or len(feature.shape) == 2 # 只能是1维或2维\n",
    "        '''\n",
    "        预测\n",
    "        输入feature可以是一个一维numpy数组也可以是一个二维numpy数组\n",
    "        如果是一维numpy（m）数组则是一个样本，包含m个特征，返回一个类别值\n",
    "        如果是二维numpy（n*m）数组则表示n个样本，每个样本包含m个特征，返回一个numpy一维数组\n",
    "        \n",
    "        提示：一种可能的实现方式为\n",
    "        if len(feature.shape) == 1: # 如果是一个样本\n",
    "            return self.traverse_node(self.root, feature) # 从根节点开始路由\n",
    "        return np.array([self.traverse_node(self.root, f) for f in feature]) # 如果是很多个样本\n",
    "        '''\n",
    "        x = np.asarray(feature)\n",
    "        preds = []\n",
    "        for i in range(x.shape[0]):\n",
    "            preds.append(self.traverse_node(self.root, x[i]))\n",
    "        return np.array(preds)\n",
    "\n",
    "\n",
    "# 定义决策树模型，传入算法参数\n",
    "DT = DecisionTree(classes=[0,1], features=feature_names, max_depth=2, min_samples_split=10, impurity_t='entropy')\n",
    "\n",
    "DT.fit(x_train, y_train, x_val, y_val) # 在训练集上训练\n",
    "p_test = DT.predict(x_test) # 在测试集上预测，获得预测值\n",
    "print(p_test) # 输出预测值\n",
    "test_acc = accuracy_score(p_test, y_test) # 将测试预测值与测试集标签对比获得准确率\n",
    "print('accuracy: {:.4f}'.format(test_acc)) # 输出准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型调优\n",
    "第一次模型测试结果可能不够好，可以先检查调试代码是否有bug，再尝试调整参数或者优化计算方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "一个完整的机器学习任务包括：确定任务、数据分析、特征工程、数据集划分、模型设计、模型训练和效果测试、结果分析和调优等多个阶段，本案例以英雄联盟游戏胜负预测任务为例，给出了每个阶段的一些简单例子，帮助大家入门机器学习，希望大家有所收获！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
